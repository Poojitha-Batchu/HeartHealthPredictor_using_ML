----------------- HeartDisease.ipynb ---------------------------------

Text cell <undefined>
# %% [markdown]
#### Importing Libraries

Code cell <undefined>
# %% [code]
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

Text cell <undefined>
# %% [markdown]
#### Loading data into the dataframe

Code cell <undefined>
# %% [code]
df = pd.read_csv('models/dataset.csv')
df
Execution output
6KB
	text/plain
		age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \
		0     63    1   3       145   233    1        0      150      0      2.3   
		1     37    1   2       130   250    0        1      187      0      3.5   
		2     41    0   1       130   204    0        0      172      0      1.4   
		3     56    1   1       120   236    0        1      178      0      0.8   
		4     57    0   0       120   354    0        1      163      1      0.6   
		..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   
		298   57    0   0       140   241    0        1      123      1      0.2   
		299   45    1   3       110   264    0        1      132      0      1.2   
		300   68    1   0       144   193    1        1      141      0      3.4   
		301   57    1   0       130   131    0        1      115      1      1.2   
		302   57    0   1       130   236    0        0      174      0      0.0   
		
		     slope  ca  thal  target  
		0        0   0     1       1  
		1        0   0     2       1  
		2        2   0     2       1  
		3        2   0     2       1  
		4        2   0     2       1  
		..     ...  ..   ...     ...  
		298      1   0     3       0  
		299      1   0     3       0  
		300      1   2     3       0  
		301      1   1     3       0  
		302      1   1     2       0  
		
		[303 rows x 14 columns]

Text cell <undefined>
# %% [markdown]
## Attribute Information:

1. age
2. sex
3. chest pain type (4 values)
4. resting blood pressure
5. serum cholestoral in mg/dl
6. fasting blood sugar > 120 mg/dl
7. resting electrocardiographic results (values 0,1,2)
8. maximum heart rate achieved
9. exercise induced angina
10. oldpeak = ST depression induced by exercise relative to rest
11. the slope of the peak exercise ST segment
12. number of major vessels (0-3) colored by flourosopy
13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect
14. target


The "target" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.


Code cell <undefined>
# %% [code]
df.columns
Execution output
0KB
	text/plain
		Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',
		       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],
		      dtype='object')

Code cell <undefined>
# %% [code]
df.head()
Execution output
3KB
	text/plain
		age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \
		0   63    1   3       145   233    1        0      150      0      2.3      0   
		1   37    1   2       130   250    0        1      187      0      3.5      0   
		2   41    0   1       130   204    0        0      172      0      1.4      2   
		3   56    1   1       120   236    0        1      178      0      0.8      2   
		4   57    0   0       120   354    0        1      163      1      0.6      2   
		
		   ca  thal  target  
		0   0     1       1  
		1   0     2       1  
		2   0     2       1  
		3   0     2       1  
		4   0     2       1

Code cell <undefined>
# %% [code]
df.tail()
Execution output
3KB
	text/plain
		age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \
		298   57    0   0       140   241    0        1      123      1      0.2   
		299   45    1   3       110   264    0        1      132      0      1.2   
		300   68    1   0       144   193    1        1      141      0      3.4   
		301   57    1   0       130   131    0        1      115      1      1.2   
		302   57    0   1       130   236    0        0      174      0      0.0   
		
		     slope  ca  thal  target  
		298      1   0     3       0  
		299      1   0     3       0  
		300      1   2     3       0  
		301      1   1     3       0  
		302      1   1     2       0

Code cell <undefined>
# %% [code]
#Number of rows and columns in the dataset
df.shape
Execution output
0KB
	text/plain
		(303, 14)

Code cell <undefined>
# %% [code]
df.info()
Execution output
1KB
	Stream
		<class 'pandas.core.frame.DataFrame'>
		RangeIndex: 303 entries, 0 to 302
		Data columns (total 14 columns):
		 #   Column    Non-Null Count  Dtype  
		---  ------    --------------  -----  
		 0   age       303 non-null    int64  
		 1   sex       303 non-null    int64  
		 2   cp        303 non-null    int64  
		 3   trestbps  303 non-null    int64  
		 4   chol      303 non-null    int64  
		 5   fbs       303 non-null    int64  
		 6   restecg   303 non-null    int64  
		 7   thalach   303 non-null    int64  
		 8   exang     303 non-null    int64  
		 9   oldpeak   303 non-null    float64
		 10  slope     303 non-null    int64  
		 11  ca        303 non-null    int64  
		 12  thal      303 non-null    int64  
		 13  target    303 non-null    int64  
		dtypes: float64(1), int64(13)
		memory usage: 33.3 KB

Code cell <undefined>
# %% [code]
df.isnull().sum()
Execution output
0KB
	text/plain
		age         0
		sex         0
		cp          0
		trestbps    0
		chol        0
		fbs         0
		restecg     0
		thalach     0
		exang       0
		oldpeak     0
		slope       0
		ca          0
		thal        0
		target      0
		dtype: int64

Code cell <undefined>
# %% [code]
df.describe()
Execution output
6KB
	text/plain
		age         sex          cp    trestbps        chol         fbs  \
		count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   
		mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   
		std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   
		min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   
		25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   
		50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   
		75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   
		max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   
		
		          restecg     thalach       exang     oldpeak       slope          ca  \
		count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   
		mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   
		std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   
		min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   
		25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   
		50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   
		75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   
		max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   
		
		             thal      target  
		count  303.000000  303.000000  
		mean     2.313531    0.544554  
		std      0.612277    0.498835  
		min      0.000000    0.000000  
		25%      2.000000    0.000000  
		50%      2.000000    1.000000  
		75%      3.000000    1.000000  
		max      3.000000    1.000000

Code cell <undefined>
# %% [code]
# chekcing the distribution of target variable

df['target'].value_counts()
Execution output
0KB
	text/plain
		target
		1    165
		0    138
		Name: count, dtype: int64

Text cell <undefined>
# %% [markdown]
1 --> Defective heart
0 --> Healthy heart


Text cell <undefined>
# %% [markdown]
#### Data visualization


Code cell <undefined>
# %% [code]
# Create blood pressure (trestbps) ranges
bins = [94, 120, 140, 160, 200]  # Define range bins
label = ['94-120', '121-140', '141-160', '161-200']  # Corresponding labels



df1 = pd.DataFrame()
df1['bp_range'] = pd.cut(df['trestbps'], bins=bins, labels=label, include_lowest=True)

df1['target'] = df['target']
# Count of disease occurrences by blood pressure range and target
disease_counts = df1.groupby(['bp_range', 'target'], observed=False).size().unstack()

print(df1)
print(disease_counts)
# df.drop(columns = ['bp_range'], inplace=True, axis=1)

Execution output
0KB
	Stream
		bp_range  target
		0    141-160       1
		1    121-140       1
		2    121-140       1
		3     94-120       1
		4     94-120       1
		..       ...     ...
		298  121-140       0
		299   94-120       0
		300  141-160       0
		301  121-140       0
		302  121-140       0
		
		[303 rows x 2 columns]
		target     0   1
		bp_range        
		94-120    37  60
		121-140   63  78
		141-160   27  23
		161-200   11   4

Code cell <undefined>
# %% [code]
# Plot bar chart
disease_counts.plot(kind='bar', stacked=False, figsize=(10, 5))

# Add title and labels
plt.title('Blood Pressure Range vs Disease', fontsize=14)
plt.xlabel('Blood Pressure Range', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks(rotation=0, fontsize=10)
plt.legend(title='Disease (Target)', labels=['No Disease', 'Disease'], fontsize=10)
plt.tight_layout()

# Display plot
plt.show()
Execution output
37KB
	text/plain
		<Figure size 1000x500 with 1 Axes>

Code cell <undefined>
# %% [code]
# Count of disease occurrences by chest pain type and target
disease_counts = df.groupby(['cp', 'target']).size().unstack()

# Plot bar chart
disease_counts.plot(kind='bar', stacked=False, figsize=(10, 6))
print(disease_counts)

# Add title and labels
plt.title('Chest Pain Type vs Disease', fontsize=14)
plt.xlabel('Chest Pain Type (4 values)', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks(rotation=0, fontsize=10)
plt.legend(title='Disease (Target)', labels=['No Disease', 'Disease'], fontsize=10)
plt.tight_layout()

# Display plot
plt.show()
Execution output
33KB
	Stream
		target    0   1
		cp             
		0       104  39
		1         9  41
		2        18  69
		3         7  16
	text/plain
		<Figure size 1000x600 with 1 Axes>

Code cell <undefined>
# %% [code]
# Create blood pressure (trestbps) ranges
bins = [126, 180, 234, 288, 342, 396, 450, 504, 564]  # Define range bins
labels = ['126-179', '180-233', '234-287', '288-341', '342-395', '396-449', '450-503', '504-564']  # Corresponding labels

df2 = pd.DataFrame()
df2['cholestoral_range'] = pd.cut(df['chol'], bins=bins, labels=labels, include_lowest=True)
df2['target'] = df['target']
print(df2)

# Count of disease occurrences by blood pressure range and target
disease_counts = df2.groupby(['cholestoral_range', 'target'], observed=False).size().unstack()
print(disease_counts)

Execution output
1KB
	Stream
		cholestoral_range  target
		0             180-233       1
		1             234-287       1
		2             180-233       1
		3             234-287       1
		4             342-395       1
		..                ...     ...
		298           234-287       0
		299           234-287       0
		300           180-233       0
		301           126-179       0
		302           234-287       0
		
		[303 rows x 2 columns]
		target              0   1
		cholestoral_range        
		126-179            11  13
		180-233            44  70
		234-287            54  55
		288-341            26  22
		342-395             1   3
		396-449             2   1
		450-503             0   0
		504-564             0   1

Code cell <undefined>
# %% [code]
# Plot bar chart
disease_counts.plot(kind='bar', stacked=False, figsize=(10, 5))

# Add title and labels
plt.title('Serum cholestoral Range vs Disease', fontsize=14)
plt.xlabel('Serum cholestoral Range', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks(rotation=0, fontsize=10)
plt.legend(title='Disease (Target)', labels=['No Disease', 'Disease'], fontsize=10)
plt.tight_layout()

# Display plot
plt.show()
Execution output
42KB
	text/plain
		<Figure size 1000x500 with 1 Axes>

Code cell <undefined>
# %% [code]

# Count of disease occurrences by blood pressure range and target
disease_counts = df.groupby(['fbs', 'target']).size().unstack()

# Plot bar chart
disease_counts.plot(kind='bar', stacked=False, figsize=(10, 5))

# Add title and labels
plt.title('Blood Sugar Range vs Disease', fontsize=14)
plt.xlabel('Blood Sugar Range', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks(rotation=0, fontsize=10)
plt.legend(title='Disease (Target)', labels=['No Disease', 'Disease'], fontsize=10)
plt.tight_layout()

# Display plot
plt.show()
Execution output
33KB
	text/plain
		<Figure size 1000x500 with 1 Axes>

Text cell <undefined>
# %% [markdown]
#### Feature Extraction and Train- Test split

Code cell <undefined>
# %% [code]
df['cp'].unique()
Execution output
0KB
	text/plain
		array([3, 2, 1, 0], dtype=int64)

Code cell <undefined>
# %% [code]
df['fbs'].unique()
Execution output
0KB
	text/plain
		array([1, 0], dtype=int64)

Code cell <undefined>
# %% [code]
df['restecg'].unique()
Execution output
0KB
	text/plain
		array([0, 1, 2], dtype=int64)

Code cell <undefined>
# %% [code]
df['exang'].unique()
Execution output
0KB
	text/plain
		array([0, 1], dtype=int64)

Code cell <undefined>
# %% [code]
df['slope'].unique()
Execution output
0KB
	text/plain
		array([0, 2, 1], dtype=int64)

Code cell <undefined>
# %% [code]
df['ca'].unique()
Execution output
0KB
	text/plain
		array([0, 2, 1, 3, 4], dtype=int64)

Code cell <undefined>
# %% [code]
df['thal'].unique()
Execution output
0KB
	text/plain
		array([1, 2, 3, 0], dtype=int64)

Code cell <undefined>
# %% [code]
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

ohe_encoder = OneHotEncoder(drop='first')
standard_scaler = StandardScaler()

categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']

num_cols = [feature for feature in df.columns if feature not in categorical_cols+['target']]
num_cols
# categorical_cols

preprocessor = ColumnTransformer(
    [
        ('OneHotEncoder', ohe_encoder, categorical_cols),
        ('StandardScaler', standard_scaler, num_cols)
    ]
)


Code cell <undefined>
# %% [code]
num_cols
# categorical_cols
Execution output
0KB
	text/plain
		['age', 'trestbps', 'chol', 'thalach', 'oldpeak']

Code cell <undefined>
# %% [code]
# Splitting the features and target

from sklearn.model_selection import train_test_split

X = df.drop(columns='target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

Code cell <undefined>
# %% [code]
X_train = preprocessor.fit_transform(X_train)
X_train
Execution output
1KB
	text/plain
		array([[ 1.        ,  1.        ,  0.        , ...,  0.91403366,
		         0.53278078, -0.92086403],
		       [ 1.        ,  0.        ,  0.        , ...,  0.43952674,
		        -1.75358236, -0.19378705],
		       [ 1.        ,  0.        ,  1.        , ..., -0.30070405,
		        -0.13967897,  2.3509824 ],
		       ...,
		       [ 1.        ,  0.        ,  0.        , ..., -0.24376322,
		        -0.85696936, -0.82997941],
		       [ 1.        ,  0.        ,  0.        , ...,  0.04094093,
		        -0.27417092, -0.19378705],
		       [ 0.        ,  1.        ,  0.        , ..., -0.98399402,
		         1.29490183, -0.92086403]])

Code cell <undefined>
# %% [code]
X_test = preprocessor.transform(X_test)
X_test
Execution output
1KB
	text/plain
		array([[ 1.        ,  0.        ,  0.        , ...,  0.5534084 ,
		        -1.70875171, -0.37555629],
		       [ 1.        ,  0.        ,  0.        , ...,  0.78117172,
		         0.39828883, -0.73909479],
		       [ 1.        ,  0.        ,  1.        , ..., -2.29363312,
		         1.02591793, -0.73909479],
		       ...,
		       [ 1.        ,  0.        ,  0.        , ..., -1.02195457,
		        -0.40866287,  2.16921315],
		       [ 1.        ,  0.        ,  0.        , ...,  0.66729006,
		        -0.36383222,  1.62390542],
		       [ 1.        ,  0.        ,  0.        , ..., -0.07294073,
		        -0.99146131,  1.44213617]])

Code cell <undefined>
# %% [code]
X_train.shape, X_test.shape
Execution output
0KB
	text/plain
		((242, 22), (61, 22))

Text cell <undefined>
# %% [markdown]
#### Training and Testing with different models

Code cell <undefined>
# %% [code]
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

Code cell <undefined>
# %% [code]
models_1 = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier(),
    'Logistic': LogisticRegression(),
    'SVM': SVC()
}

models_1
Execution output
0KB
	text/plain
		{'Decision Tree': DecisionTreeClassifier(),
		 'Random Forest': RandomForestClassifier(),
		 'KNN': KNeighborsClassifier(),
		 'Logistic': LogisticRegression(),
		 'SVM': SVC()}

Code cell <undefined>
# %% [code]
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score

def evaluate_model(true, predict):
    accuracy = accuracy_score(true, predict)
    precision = precision_score(true, predict)
    recall = recall_score(true, predict)
    matrix = confusion_matrix(true, predict)

    return accuracy, precision, recall, matrix

Code cell <undefined>
# %% [code]
for i in range(len(list(models_1))):
    model = list(models_1.values())[i]
    model.fit(X_train, y_train)

    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    print(f'----- Model: {list(models_1.keys())[i]} -----')

    X_train_accuracy, X_train_precision, X_train_recall, X_train_matrix = evaluate_model(y_train, y_train_pred)
    X_test_accuracy, X_test_precision, X_test_recall, X_test_matrix = evaluate_model(y_test, y_test_pred)

    print('\n Model Training Performance:')
    print(f'Accuracy: {X_train_accuracy:.3f}')
    print(f'Precision: {X_train_precision:.3f}')
    print(f'Recall: {X_train_recall:.3f}')
    print('Confusion matrix: \n', X_train_matrix)

    print('\n Model Test Performance:')
    print(f'Accuracy: {X_test_accuracy:.3f}')
    print(f'Precision: {X_test_precision:.3f}')
    print(f'Recall: {X_test_recall:.3f}')
    print('Confusion matrix: \n', X_test_matrix)

    print("="*35)

Execution output
2KB
	Stream
		----- Model: Decision Tree -----
		
		 Model Training Performance:
		Accuracy: 1.000
		Precision: 1.000
		Recall: 1.000
		Confusion matrix: 
		 [[109   0]
		 [  0 133]]
		
		 Model Test Performance:
		Accuracy: 0.754
		Precision: 0.774
		Recall: 0.750
		Confusion matrix: 
		 [[22  7]
		 [ 8 24]]
		===================================
		----- Model: Random Forest -----
		
		 Model Training Performance:
		Accuracy: 1.000
		Precision: 1.000
		Recall: 1.000
		Confusion matrix: 
		 [[109   0]
		 [  0 133]]
		
		 Model Test Performance:
		Accuracy: 0.836
		Precision: 0.867
		Recall: 0.812
		Confusion matrix: 
		 [[25  4]
		 [ 6 26]]
		===================================
		----- Model: KNN -----
		
		 Model Training Performance:
		Accuracy: 0.864
		Precision: 0.857
		Recall: 0.902
		Confusion matrix: 
		 [[ 89  20]
		 [ 13 120]]
		
		 Model Test Performance:
		Accuracy: 0.869
		Precision: 0.900
		Recall: 0.844
		Confusion matrix: 
		 [[26  3]
		 [ 5 27]]
		===================================
		----- Model: Logistic -----
		
		 Model Training Performance:
		Accuracy: 0.868
		Precision: 0.863
		Recall: 0.902
		Confusion matrix: 
		 [[ 90  19]
		 [ 13 120]]
		
		 Model Test Performance:
		Accuracy: 0.902
		Precision: 0.933
		Recall: 0.875
		Confusion matrix: 
		 [[27  2]
		 [ 4 28]]
		===================================
		----- Model: SVM -----
		
		 Model Training Performance:
		Accuracy: 0.905
		Precision: 0.893
		Recall: 0.940
		Confusion matrix: 
		 [[ 94  15]
		 [  8 125]]
		
		 Model Test Performance:
		Accuracy: 0.869
		Precision: 0.929
		Recall: 0.812
		Confusion matrix: 
		 [[27  2]
		 [ 6 26]]
		===================================

Text cell <undefined>
# %% [markdown]
#### Hyperparameter Tuning using RandomizedSearchCV

Code cell <undefined>
# %% [code]
decision_param = {
    'criterion': ['gini', 'entropy', 'log_loss'],
    'max_depth': [2, 3, 4, 7, 9, 10],
    'min_samples_split': [2, 8, 15, 20]
}
decision_param
Execution output
0KB
	text/plain
		{'criterion': ['gini', 'entropy', 'log_loss'],
		 'max_depth': [2, 3, 4, 7, 9, 10],
		 'min_samples_split': [2, 8, 15, 20]}

Code cell <undefined>
# %% [code]
randomForest_params = {
    'n_estimators': [80, 110, 140, 150],
    'criterion': ['gini', 'entropy', 'log_loss'],
    'max_depth': [3, 5, 7, 8, 9],
    'min_samples_split': [14, 23, 13, 25]
}
randomForest_params
Execution output
0KB
	text/plain
		{'n_estimators': [80, 110, 140, 150],
		 'criterion': ['gini', 'entropy', 'log_loss'],
		 'max_depth': [3, 5, 7, 8, 9],
		 'min_samples_split': [14, 23, 13, 25]}

Code cell <undefined>
# %% [code]
knn_params = {
    'n_neighbors': [3, 4, 5, 7, 9],
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']
}
knn_params
Execution output
0KB
	text/plain
		{'n_neighbors': [3, 4, 5, 7, 9],
		 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}

Code cell <undefined>
# %% [code]
logistic_params = {
    'penalty': ['l1', 'l2', 'elasticnet', None],
    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']
}
logistic_params
Execution output
0KB
	text/plain
		{'penalty': ['l1', 'l2', 'elasticnet', None],
		 'solver': ['lbfgs',
		  'liblinear',
		  'newton-cg',
		  'newton-cholesky',
		  'sag',
		  'saga']}

Code cell <undefined>
# %% [code]
cv_models = [
    ('Decision Tree', DecisionTreeClassifier(), decision_param),
    ('Random Forest', RandomForestClassifier(), randomForest_params),
    ('Logistic', LogisticRegression(), logistic_params),
    ('KNN', KNeighborsClassifier(), knn_params)
]

cv_models
Execution output
1KB
	text/plain
		[('Decision Tree',
		  DecisionTreeClassifier(),
		  {'criterion': ['gini', 'entropy', 'log_loss'],
		   'max_depth': [2, 3, 4, 7, 9, 10],
		   'min_samples_split': [2, 8, 15, 20]}),
		 ('Random Forest',
		  RandomForestClassifier(),
		  {'n_estimators': [80, 110, 140, 150],
		   'criterion': ['gini', 'entropy', 'log_loss'],
		   'max_depth': [3, 5, 7, 8, 9],
		   'min_samples_split': [14, 23, 13, 25]}),
		 ('Logistic',
		  LogisticRegression(),
		  {'penalty': ['l1', 'l2', 'elasticnet', None],
		   'solver': ['lbfgs',
		    'liblinear',
		    'newton-cg',
		    'newton-cholesky',
		    'sag',
		    'saga']}),
		 ('KNN',
		  KNeighborsClassifier(),
		  {'n_neighbors': [3, 4, 5, 7, 9],
		   'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']})]

Code cell <undefined>
# %% [code]
import warnings
warnings.filterwarnings("ignore")


Code cell <undefined>
# %% [code]
from sklearn.model_selection import RandomizedSearchCV

model_params = {}

for name, model, params in cv_models:
    random = RandomizedSearchCV(
                estimator=model,
                param_distributions=params,
                n_iter=100,
                cv=3, verbose=2, n_jobs=-1
            )
    
    random.fit(X_train, y_train)
    model_params[name] = random.best_params_

model_params
Execution output
1KB
	Stream
		Fitting 3 folds for each of 72 candidates, totalling 216 fits
		Fitting 3 folds for each of 100 candidates, totalling 300 fits
		Fitting 3 folds for each of 24 candidates, totalling 72 fits
		Fitting 3 folds for each of 20 candidates, totalling 60 fits
	text/plain
		{'Decision Tree': {'min_samples_split': 2,
		  'max_depth': 10,
		  'criterion': 'entropy'},
		 'Random Forest': {'n_estimators': 150,
		  'min_samples_split': 13,
		  'max_depth': 9,
		  'criterion': 'entropy'},
		 'Logistic': {'solver': 'saga', 'penalty': None},
		 'KNN': {'n_neighbors': 5, 'algorithm': 'auto'}}

Code cell <undefined>
# %% [code]
for model_name in model_params:
    print(f'-------- Best params for {model_name} -----------')
    print(model_params[model_name], '\n')
Execution output
1KB
	Stream
		-------- Best params for Decision Tree -----------
		{'min_samples_split': 2, 'max_depth': 10, 'criterion': 'entropy'} 
		
		-------- Best params for Random Forest -----------
		{'n_estimators': 150, 'min_samples_split': 13, 'max_depth': 9, 'criterion': 'entropy'} 
		
		-------- Best params for Logistic -----------
		{'solver': 'saga', 'penalty': None} 
		
		-------- Best params for KNN -----------
		{'n_neighbors': 5, 'algorithm': 'auto'}

Code cell <undefined>
# %% [code]
models_2 = {
    'Decision Tree': DecisionTreeClassifier(
        min_samples_split=2, max_depth=10, criterion='entropy'
    ),
    'Random Forest': RandomForestClassifier(
        n_estimators=150, min_samples_split=13, max_depth=9, criterion='entropy'
    ),
    'Logistic': LogisticRegression(
        solver='saga', penalty=None
    ),
    'KNN': KNeighborsClassifier(
        n_neighbors=5, algorithm='auto'
    )
}

models_2
Execution output
0KB
	text/plain
		{'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=10),
		 'Random Forest': RandomForestClassifier(criterion='entropy', max_depth=9, min_samples_split=13,
		                        n_estimators=150),
		 'Logistic': LogisticRegression(penalty=None, solver='saga'),
		 'KNN': KNeighborsClassifier()}

Code cell <undefined>
# %% [code]
for i in range(len(list(models_2))):
    model = list(models_2.values())[i]
    model.fit(X_train, y_train)

    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    print(f'----- Model: {list(models_2.keys())[i]} -----')

    X_train_accuracy, X_train_precision, X_train_recall, X_train_matrix = evaluate_model(y_train, y_train_pred)
    X_test_accuracy, X_test_precision, X_test_recall, X_test_matrix = evaluate_model(y_test, y_test_pred)

    print('\n Model Training Performance:')
    print(f'Accuracy: {X_train_accuracy:.3f}')
    print(f'Precision: {X_train_precision:.3f}')
    print(f'Recall: {X_train_recall:.3f}')
    print('Confusion matrix: \n', X_train_matrix)

    print('\n Model Test Performance:')
    print(f'Accuracy: {X_test_accuracy:.3f}')
    print(f'Precision: {X_test_precision:.3f}')
    print(f'Recall: {X_test_recall:.3f}')
    print('Confusion matrix: \n', X_test_matrix)

    print("="*35)

Execution output
1KB
	Stream
		----- Model: Decision Tree -----
		
		 Model Training Performance:
		Accuracy: 0.992
		Precision: 0.985
		Recall: 1.000
		Confusion matrix: 
		 [[107   2]
		 [  0 133]]
		
		 Model Test Performance:
		Accuracy: 0.705
		Precision: 0.769
		Recall: 0.625
		Confusion matrix: 
		 [[23  6]
		 [12 20]]
		===================================
		----- Model: Random Forest -----
		
		 Model Training Performance:
		Accuracy: 0.930
		Precision: 0.914
		Recall: 0.962
		Confusion matrix: 
		 [[ 97  12]
		 [  5 128]]
		
		 Model Test Performance:
		Accuracy: 0.852
		Precision: 0.897
		Recall: 0.812
		Confusion matrix: 
		 [[26  3]
		 [ 6 26]]
		===================================
		----- Model: Logistic -----
		
		 Model Training Performance:
		Accuracy: 0.876
		Precision: 0.871
		Recall: 0.910
		Confusion matrix: 
		 [[ 91  18]
		 [ 12 121]]
		
		 Model Test Performance:
		Accuracy: 0.885
		Precision: 0.903
		Recall: 0.875
		Confusion matrix: 
		 [[26  3]
		 [ 4 28]]
		===================================
		----- Model: KNN -----
		
		 Model Training Performance:
		Accuracy: 0.864
		Precision: 0.857
		Recall: 0.902
		Confusion matrix: 
		 [[ 89  20]
		 [ 13 120]]
		
		 Model Test Performance:
		Accuracy: 0.869
		Precision: 0.900
		Recall: 0.844
		Confusion matrix: 
		 [[26  3]
		 [ 5 27]]
		===================================

Text cell <undefined>
# %% [markdown]
##### Logistic Regression, without hyperparameter tuning, is achieving the highest accuracy, precision, and recall among all models. Therefore, I have decided to proceed with Logistic Regression. 

Text cell <undefined>
# %% [markdown]
#### Converting Logistic model, preprocessor columnTransformer into pickle file

Code cell <undefined>
# %% [code]
models_1['Logistic']
Execution output
14KB
	text/plain
		LogisticRegression()

Code cell <undefined>
# %% [code]
import pickle
pickle.dump(preprocessor, open('columnTransformer.pkl', 'wb'))
pickle.dump(models_1['Logistic'], open('logisticModel.pkl', 'wb'))

Text cell <undefined>
# %% [markdown]
#### Testing with own values

Code cell <undefined>
# %% [code]
inputs = [57, 1, 0, 150, 276, 0, 0, 112, 1, 0, 1, 1, 1]
inputs_reshaped = np.array(inputs).reshape(1, -1)

columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','exang', 'oldpeak', 'slope', 'ca', 'thal']
new_df = pd.DataFrame(data=inputs_reshaped, columns=columns)
new_scaled_data = preprocessor.transform(new_df)
pd.DataFrame(new_scaled_data)
Execution output
2KB
	text/plain
		0    1    2    3    4    5    6    7    8    9   ...   12   13   14   15  \
		0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  1.0  0.0   
		
		    16        17        18        19        20        21  
		0  0.0  0.276218  1.169491  0.553408 -1.708752 -0.920864  
		
		[1 rows x 22 columns]

Code cell <undefined>
# %% [code]
y_pred = models_1['Logistic'].predict(new_scaled_data)
y_pred
Execution output
0KB
	text/plain
		array([0], dtype=int64)

Code cell <undefined>
# %% [code]



-------------- app.py -------------------

from flask import Flask, render_template, request
import pickle
import pandas as pd

app = Flask(__name__)

logisticModel = pickle.load(open('models/logisticModel.pkl', 'rb'))
columnTransformer = pickle.load(open('models/columnTransformer.pkl', 'rb'))

@app.route('/', methods=['GET', 'POST'])
def index():
    result = None
    if request.method == 'POST':
        age = int(request.form.get('age'))
        gender = int(request.form.get('gender'))
        chest_pain_type = int(request.form.get('chest_pain_type'))
        blood_pressure = int(request.form.get('blood_pressure'))
        cholestoral = int(request.form.get('cholestoral'))
        blood_sugar = int(request.form.get('blood_sugar'))
        cardiographic = int(request.form.get('cardiographic'))
        heart_rate = int(request.form.get('heart_rate'))
        angina = int(request.form.get('angina'))
        oldpeak = round(float(request.form.get('oldpeak')), 1)
        slope = int(request.form.get('slope'))
        vessels = int(request.form.get('vessels'))
        thal = int(request.form.get('thal'))

        inputs = [[age, gender, chest_pain_type, blood_pressure, cholestoral, blood_sugar, cardiographic, heart_rate, angina, oldpeak, slope, vessels, thal]]
        columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','exang', 'oldpeak', 'slope', 'ca', 'thal']
        new_df = pd.DataFrame(data=inputs, columns=columns)
        new_scaled_data = columnTransformer.transform(new_df)

        result = "Healthy" if logisticModel.predict(new_scaled_data) == 0 else "Not Healthy"
        print(result)
        return render_template('index.html', result=result)
    
    return render_template('index.html', result=None)


if __name__ == '__main__':
    app.run(debug=True)



#7DDA58 = Green
